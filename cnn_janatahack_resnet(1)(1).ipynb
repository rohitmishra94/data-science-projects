{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_janatahack_resnet(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2KVkhVR-9HC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset for the project\n",
        "#----https://drive.google.com/drive/folders/1fVr-DyfxqtmFuvbvniOiL1eS9b3kwgNe?usp=sharing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7tGnpFNINxn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "87043f2a-a72c-44b3-d935-67a7b77a1f26"
      },
      "source": [
        "# mounting drive to access files in drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blN2EGUbHkf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run if zip file uploaded in colab \n",
        "\n",
        "from zipfile import ZipFile\n",
        "file_name = file_path\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAsJHuKfOnLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqJ4Ra6qOnHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model=tf.keras.applications.InceptionV3(input_shape=(224,224,3),weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmmhcMdohjYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a9fb8efe-5b64-4a40-ab75-adb4752b1a24"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 25, 25, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 25, 25, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 25, 25, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 25, 25, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 25, 25, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 25, 25, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 25, 25, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 25, 25, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 25, 25, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 25, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 25, 25, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 25, 25, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 25, 25, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 25, 25, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWNn95DhOnE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2meHvu9YOnB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=base_model.get_layer('mixed10').output\n",
        "x=layers.GlobalMaxPool2D()(x)\n",
        "x=layers.Flatten()(x)\n",
        "\n",
        "\n",
        "x=layers.Dense(4096)(x)\n",
        "x=layers.Dense(4096)(x)\n",
        "\n",
        "\n",
        "x=layers.Dropout(0.2)(x)\n",
        "\n",
        "\n",
        "output=layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model=Model(base_model.input,output)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JcnXvdHwPhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00000001),metrics=['accuracy'],loss='binary_crossentropy')\n",
        "\n",
        "callbacks=tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=3,restore_best_weights=True)\n",
        "\n",
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9aVzVu_Om_d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2ba3360f-368d-425b-b994-e2923ac0b446"
      },
      "source": [
        "training=ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "validation=ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = training.flow_from_directory('/content/gdrive/My Drive/datasets/cnn_emergency_or_not/train',\n",
        "                                                    batch_size = 8,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (224, 224))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  validation.flow_from_directory( '/content/gdrive/My Drive/datasets/cnn_emergency_or_not/validation',\n",
        "                                                          batch_size  = 8,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (224, 224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1316 images belonging to 2 classes.\n",
            "Found 330 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psyEe5VvOm8t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b28191cf-0556-49fd-82ca-5cdb7bd645d4"
      },
      "source": [
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            epochs = 200,\n",
        "            callbacks=[model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "165/165 [==============================] - 23s 139ms/step - loss: 1.7654 - accuracy: 0.4514 - val_loss: 1.3070 - val_accuracy: 0.4303\n",
            "Epoch 2/200\n",
            "165/165 [==============================] - 22s 134ms/step - loss: 1.3959 - accuracy: 0.4863 - val_loss: 1.0292 - val_accuracy: 0.4697\n",
            "Epoch 3/200\n",
            "165/165 [==============================] - 21s 130ms/step - loss: 1.1371 - accuracy: 0.5015 - val_loss: 0.8360 - val_accuracy: 0.5303\n",
            "Epoch 4/200\n",
            "165/165 [==============================] - 22s 132ms/step - loss: 1.0121 - accuracy: 0.5304 - val_loss: 0.7324 - val_accuracy: 0.6121\n",
            "Epoch 5/200\n",
            "165/165 [==============================] - 22s 131ms/step - loss: 0.9141 - accuracy: 0.5798 - val_loss: 0.6715 - val_accuracy: 0.6636\n",
            "Epoch 6/200\n",
            "165/165 [==============================] - 22s 132ms/step - loss: 0.8590 - accuracy: 0.5813 - val_loss: 0.6394 - val_accuracy: 0.6909\n",
            "Epoch 7/200\n",
            "165/165 [==============================] - 22s 134ms/step - loss: 0.8270 - accuracy: 0.6064 - val_loss: 0.6200 - val_accuracy: 0.7121\n",
            "Epoch 8/200\n",
            "165/165 [==============================] - 22s 132ms/step - loss: 0.7793 - accuracy: 0.6315 - val_loss: 0.6050 - val_accuracy: 0.7182\n",
            "Epoch 9/200\n",
            "165/165 [==============================] - 22s 133ms/step - loss: 0.7815 - accuracy: 0.6368 - val_loss: 0.5917 - val_accuracy: 0.7242\n",
            "Epoch 10/200\n",
            "165/165 [==============================] - 22s 135ms/step - loss: 0.8006 - accuracy: 0.6299 - val_loss: 0.5794 - val_accuracy: 0.7394\n",
            "Epoch 11/200\n",
            "165/165 [==============================] - 22s 131ms/step - loss: 0.7649 - accuracy: 0.6550 - val_loss: 0.5675 - val_accuracy: 0.7455\n",
            "Epoch 12/200\n",
            "165/165 [==============================] - 21s 125ms/step - loss: 0.7359 - accuracy: 0.6550 - val_loss: 0.5560 - val_accuracy: 0.7455\n",
            "Epoch 13/200\n",
            "165/165 [==============================] - 22s 131ms/step - loss: 0.7451 - accuracy: 0.6558 - val_loss: 0.5419 - val_accuracy: 0.7545\n",
            "Epoch 14/200\n",
            "165/165 [==============================] - 22s 132ms/step - loss: 0.7498 - accuracy: 0.6474 - val_loss: 0.5303 - val_accuracy: 0.7576\n",
            "Epoch 15/200\n",
            "165/165 [==============================] - 22s 132ms/step - loss: 0.6875 - accuracy: 0.6664 - val_loss: 0.5191 - val_accuracy: 0.7667\n",
            "Epoch 16/200\n",
            "165/165 [==============================] - 22s 133ms/step - loss: 0.6721 - accuracy: 0.6641 - val_loss: 0.5091 - val_accuracy: 0.7788\n",
            "Epoch 17/200\n",
            "165/165 [==============================] - 22s 133ms/step - loss: 0.7083 - accuracy: 0.6733 - val_loss: 0.4977 - val_accuracy: 0.7818\n",
            "Epoch 18/200\n",
            "165/165 [==============================] - 22s 131ms/step - loss: 0.7165 - accuracy: 0.6710 - val_loss: 0.4879 - val_accuracy: 0.7879\n",
            "Epoch 19/200\n",
            "165/165 [==============================] - 22s 130ms/step - loss: 0.6711 - accuracy: 0.6854 - val_loss: 0.4769 - val_accuracy: 0.8000\n",
            "Epoch 20/200\n",
            "165/165 [==============================] - 20s 124ms/step - loss: 0.6810 - accuracy: 0.6831 - val_loss: 0.4673 - val_accuracy: 0.7970\n",
            "Epoch 21/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.6468 - accuracy: 0.7120 - val_loss: 0.4575 - val_accuracy: 0.7970\n",
            "Epoch 22/200\n",
            "165/165 [==============================] - 22s 132ms/step - loss: 0.6450 - accuracy: 0.7082 - val_loss: 0.4487 - val_accuracy: 0.8061\n",
            "Epoch 23/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.6169 - accuracy: 0.7150 - val_loss: 0.4403 - val_accuracy: 0.8061\n",
            "Epoch 24/200\n",
            "165/165 [==============================] - 21s 128ms/step - loss: 0.6095 - accuracy: 0.7090 - val_loss: 0.4324 - val_accuracy: 0.8121\n",
            "Epoch 25/200\n",
            "165/165 [==============================] - 21s 127ms/step - loss: 0.6065 - accuracy: 0.7226 - val_loss: 0.4250 - val_accuracy: 0.8182\n",
            "Epoch 26/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.6119 - accuracy: 0.7082 - val_loss: 0.4170 - val_accuracy: 0.8182\n",
            "Epoch 27/200\n",
            "165/165 [==============================] - 21s 127ms/step - loss: 0.5877 - accuracy: 0.7280 - val_loss: 0.4100 - val_accuracy: 0.8273\n",
            "Epoch 28/200\n",
            "165/165 [==============================] - 22s 133ms/step - loss: 0.5620 - accuracy: 0.7409 - val_loss: 0.4037 - val_accuracy: 0.8303\n",
            "Epoch 29/200\n",
            "165/165 [==============================] - 21s 128ms/step - loss: 0.5767 - accuracy: 0.7401 - val_loss: 0.3974 - val_accuracy: 0.8333\n",
            "Epoch 30/200\n",
            "165/165 [==============================] - 21s 127ms/step - loss: 0.6101 - accuracy: 0.7325 - val_loss: 0.3915 - val_accuracy: 0.8394\n",
            "Epoch 31/200\n",
            "165/165 [==============================] - 20s 124ms/step - loss: 0.5918 - accuracy: 0.7181 - val_loss: 0.3846 - val_accuracy: 0.8394\n",
            "Epoch 32/200\n",
            "165/165 [==============================] - 21s 128ms/step - loss: 0.6111 - accuracy: 0.7295 - val_loss: 0.3786 - val_accuracy: 0.8394\n",
            "Epoch 33/200\n",
            "165/165 [==============================] - 21s 128ms/step - loss: 0.5871 - accuracy: 0.7401 - val_loss: 0.3728 - val_accuracy: 0.8424\n",
            "Epoch 34/200\n",
            "165/165 [==============================] - 20s 120ms/step - loss: 0.5570 - accuracy: 0.7568 - val_loss: 0.3681 - val_accuracy: 0.8424\n",
            "Epoch 35/200\n",
            "165/165 [==============================] - 21s 127ms/step - loss: 0.5870 - accuracy: 0.7371 - val_loss: 0.3634 - val_accuracy: 0.8455\n",
            "Epoch 36/200\n",
            "165/165 [==============================] - 22s 132ms/step - loss: 0.5355 - accuracy: 0.7553 - val_loss: 0.3585 - val_accuracy: 0.8485\n",
            "Epoch 37/200\n",
            "165/165 [==============================] - 21s 129ms/step - loss: 0.5351 - accuracy: 0.7599 - val_loss: 0.3538 - val_accuracy: 0.8515\n",
            "Epoch 38/200\n",
            "165/165 [==============================] - 21s 128ms/step - loss: 0.5271 - accuracy: 0.7576 - val_loss: 0.3489 - val_accuracy: 0.8545\n",
            "Epoch 39/200\n",
            "165/165 [==============================] - 21s 130ms/step - loss: 0.5539 - accuracy: 0.7568 - val_loss: 0.3446 - val_accuracy: 0.8576\n",
            "Epoch 40/200\n",
            "165/165 [==============================] - 22s 131ms/step - loss: 0.4927 - accuracy: 0.7713 - val_loss: 0.3409 - val_accuracy: 0.8606\n",
            "Epoch 41/200\n",
            "165/165 [==============================] - 21s 130ms/step - loss: 0.5467 - accuracy: 0.7675 - val_loss: 0.3366 - val_accuracy: 0.8667\n",
            "Epoch 42/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.5277 - accuracy: 0.7568 - val_loss: 0.3329 - val_accuracy: 0.8667\n",
            "Epoch 43/200\n",
            "165/165 [==============================] - 21s 129ms/step - loss: 0.4919 - accuracy: 0.7743 - val_loss: 0.3293 - val_accuracy: 0.8758\n",
            "Epoch 44/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4793 - accuracy: 0.7956 - val_loss: 0.3258 - val_accuracy: 0.8758\n",
            "Epoch 45/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4942 - accuracy: 0.7827 - val_loss: 0.3225 - val_accuracy: 0.8758\n",
            "Epoch 46/200\n",
            "165/165 [==============================] - 22s 131ms/step - loss: 0.4928 - accuracy: 0.7774 - val_loss: 0.3189 - val_accuracy: 0.8788\n",
            "Epoch 47/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.5056 - accuracy: 0.7774 - val_loss: 0.3159 - val_accuracy: 0.8727\n",
            "Epoch 48/200\n",
            "165/165 [==============================] - 20s 120ms/step - loss: 0.5037 - accuracy: 0.7804 - val_loss: 0.3127 - val_accuracy: 0.8788\n",
            "Epoch 49/200\n",
            "165/165 [==============================] - 20s 120ms/step - loss: 0.5146 - accuracy: 0.7743 - val_loss: 0.3097 - val_accuracy: 0.8788\n",
            "Epoch 50/200\n",
            "165/165 [==============================] - 21s 128ms/step - loss: 0.5088 - accuracy: 0.7857 - val_loss: 0.3068 - val_accuracy: 0.8879\n",
            "Epoch 51/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.5049 - accuracy: 0.7766 - val_loss: 0.3041 - val_accuracy: 0.8879\n",
            "Epoch 52/200\n",
            "165/165 [==============================] - 21s 127ms/step - loss: 0.5032 - accuracy: 0.7675 - val_loss: 0.3012 - val_accuracy: 0.8909\n",
            "Epoch 53/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4614 - accuracy: 0.7948 - val_loss: 0.2986 - val_accuracy: 0.8909\n",
            "Epoch 54/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4913 - accuracy: 0.7903 - val_loss: 0.2960 - val_accuracy: 0.8909\n",
            "Epoch 55/200\n",
            "165/165 [==============================] - 21s 129ms/step - loss: 0.4994 - accuracy: 0.7728 - val_loss: 0.2937 - val_accuracy: 0.8970\n",
            "Epoch 56/200\n",
            "165/165 [==============================] - 21s 130ms/step - loss: 0.4703 - accuracy: 0.8123 - val_loss: 0.2914 - val_accuracy: 0.9000\n",
            "Epoch 57/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4867 - accuracy: 0.8024 - val_loss: 0.2890 - val_accuracy: 0.8970\n",
            "Epoch 58/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4961 - accuracy: 0.7834 - val_loss: 0.2869 - val_accuracy: 0.8970\n",
            "Epoch 59/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4602 - accuracy: 0.7888 - val_loss: 0.2847 - val_accuracy: 0.8970\n",
            "Epoch 60/200\n",
            "165/165 [==============================] - 20s 120ms/step - loss: 0.4570 - accuracy: 0.8123 - val_loss: 0.2826 - val_accuracy: 0.9000\n",
            "Epoch 61/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.4584 - accuracy: 0.8108 - val_loss: 0.2806 - val_accuracy: 0.9000\n",
            "Epoch 62/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4809 - accuracy: 0.7933 - val_loss: 0.2788 - val_accuracy: 0.9000\n",
            "Epoch 63/200\n",
            "165/165 [==============================] - 21s 130ms/step - loss: 0.4646 - accuracy: 0.7956 - val_loss: 0.2768 - val_accuracy: 0.9030\n",
            "Epoch 64/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.4445 - accuracy: 0.8153 - val_loss: 0.2750 - val_accuracy: 0.8970\n",
            "Epoch 65/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.4330 - accuracy: 0.8161 - val_loss: 0.2735 - val_accuracy: 0.8970\n",
            "Epoch 66/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.4846 - accuracy: 0.7819 - val_loss: 0.2720 - val_accuracy: 0.8970\n",
            "Epoch 67/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4333 - accuracy: 0.8116 - val_loss: 0.2708 - val_accuracy: 0.9000\n",
            "Epoch 68/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4265 - accuracy: 0.8146 - val_loss: 0.2688 - val_accuracy: 0.9030\n",
            "Epoch 69/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4635 - accuracy: 0.8070 - val_loss: 0.2671 - val_accuracy: 0.9030\n",
            "Epoch 70/200\n",
            "165/165 [==============================] - 22s 131ms/step - loss: 0.4706 - accuracy: 0.8017 - val_loss: 0.2656 - val_accuracy: 0.9061\n",
            "Epoch 71/200\n",
            "165/165 [==============================] - 22s 130ms/step - loss: 0.4614 - accuracy: 0.8040 - val_loss: 0.2644 - val_accuracy: 0.9121\n",
            "Epoch 72/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.4133 - accuracy: 0.8184 - val_loss: 0.2633 - val_accuracy: 0.9121\n",
            "Epoch 73/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.4400 - accuracy: 0.8153 - val_loss: 0.2621 - val_accuracy: 0.9121\n",
            "Epoch 74/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.4269 - accuracy: 0.8191 - val_loss: 0.2608 - val_accuracy: 0.9091\n",
            "Epoch 75/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.4120 - accuracy: 0.8290 - val_loss: 0.2594 - val_accuracy: 0.9121\n",
            "Epoch 76/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.4225 - accuracy: 0.8116 - val_loss: 0.2581 - val_accuracy: 0.9121\n",
            "Epoch 77/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4512 - accuracy: 0.8017 - val_loss: 0.2569 - val_accuracy: 0.9121\n",
            "Epoch 78/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.4210 - accuracy: 0.8176 - val_loss: 0.2560 - val_accuracy: 0.9121\n",
            "Epoch 79/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.4284 - accuracy: 0.8199 - val_loss: 0.2550 - val_accuracy: 0.9091\n",
            "Epoch 80/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4585 - accuracy: 0.8131 - val_loss: 0.2539 - val_accuracy: 0.9121\n",
            "Epoch 81/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4224 - accuracy: 0.8161 - val_loss: 0.2527 - val_accuracy: 0.9121\n",
            "Epoch 82/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.4504 - accuracy: 0.8131 - val_loss: 0.2518 - val_accuracy: 0.9121\n",
            "Epoch 83/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4280 - accuracy: 0.8123 - val_loss: 0.2508 - val_accuracy: 0.9121\n",
            "Epoch 84/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4439 - accuracy: 0.8245 - val_loss: 0.2497 - val_accuracy: 0.9121\n",
            "Epoch 85/200\n",
            "165/165 [==============================] - 21s 130ms/step - loss: 0.4072 - accuracy: 0.8290 - val_loss: 0.2489 - val_accuracy: 0.9152\n",
            "Epoch 86/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.4203 - accuracy: 0.8252 - val_loss: 0.2478 - val_accuracy: 0.9121\n",
            "Epoch 87/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4122 - accuracy: 0.8237 - val_loss: 0.2467 - val_accuracy: 0.9121\n",
            "Epoch 88/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.4306 - accuracy: 0.8275 - val_loss: 0.2460 - val_accuracy: 0.9152\n",
            "Epoch 89/200\n",
            "165/165 [==============================] - 21s 129ms/step - loss: 0.4480 - accuracy: 0.8245 - val_loss: 0.2449 - val_accuracy: 0.9182\n",
            "Epoch 90/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.4093 - accuracy: 0.8153 - val_loss: 0.2440 - val_accuracy: 0.9182\n",
            "Epoch 91/200\n",
            "165/165 [==============================] - 20s 124ms/step - loss: 0.3960 - accuracy: 0.8351 - val_loss: 0.2432 - val_accuracy: 0.9182\n",
            "Epoch 92/200\n",
            "165/165 [==============================] - 20s 120ms/step - loss: 0.4242 - accuracy: 0.8252 - val_loss: 0.2424 - val_accuracy: 0.9182\n",
            "Epoch 93/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4074 - accuracy: 0.8298 - val_loss: 0.2419 - val_accuracy: 0.9182\n",
            "Epoch 94/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3930 - accuracy: 0.8359 - val_loss: 0.2410 - val_accuracy: 0.9182\n",
            "Epoch 95/200\n",
            "165/165 [==============================] - 20s 120ms/step - loss: 0.4313 - accuracy: 0.8214 - val_loss: 0.2406 - val_accuracy: 0.9152\n",
            "Epoch 96/200\n",
            "165/165 [==============================] - 20s 120ms/step - loss: 0.3933 - accuracy: 0.8473 - val_loss: 0.2400 - val_accuracy: 0.9152\n",
            "Epoch 97/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3794 - accuracy: 0.8473 - val_loss: 0.2393 - val_accuracy: 0.9152\n",
            "Epoch 98/200\n",
            "165/165 [==============================] - 20s 119ms/step - loss: 0.4210 - accuracy: 0.8313 - val_loss: 0.2393 - val_accuracy: 0.9152\n",
            "Epoch 99/200\n",
            "165/165 [==============================] - 20s 120ms/step - loss: 0.3887 - accuracy: 0.8450 - val_loss: 0.2383 - val_accuracy: 0.9152\n",
            "Epoch 100/200\n",
            "165/165 [==============================] - 22s 132ms/step - loss: 0.3815 - accuracy: 0.8359 - val_loss: 0.2374 - val_accuracy: 0.9182\n",
            "Epoch 101/200\n",
            "165/165 [==============================] - 21s 129ms/step - loss: 0.3743 - accuracy: 0.8457 - val_loss: 0.2358 - val_accuracy: 0.9212\n",
            "Epoch 102/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3990 - accuracy: 0.8313 - val_loss: 0.2352 - val_accuracy: 0.9182\n",
            "Epoch 103/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4047 - accuracy: 0.8283 - val_loss: 0.2342 - val_accuracy: 0.9212\n",
            "Epoch 104/200\n",
            "165/165 [==============================] - 20s 120ms/step - loss: 0.3937 - accuracy: 0.8343 - val_loss: 0.2334 - val_accuracy: 0.9212\n",
            "Epoch 105/200\n",
            "165/165 [==============================] - 20s 120ms/step - loss: 0.4300 - accuracy: 0.8267 - val_loss: 0.2326 - val_accuracy: 0.9182\n",
            "Epoch 106/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3952 - accuracy: 0.8336 - val_loss: 0.2321 - val_accuracy: 0.9212\n",
            "Epoch 107/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3792 - accuracy: 0.8412 - val_loss: 0.2317 - val_accuracy: 0.9212\n",
            "Epoch 108/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3763 - accuracy: 0.8579 - val_loss: 0.2313 - val_accuracy: 0.9212\n",
            "Epoch 109/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.4037 - accuracy: 0.8290 - val_loss: 0.2306 - val_accuracy: 0.9212\n",
            "Epoch 110/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3853 - accuracy: 0.8404 - val_loss: 0.2302 - val_accuracy: 0.9212\n",
            "Epoch 111/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3821 - accuracy: 0.8397 - val_loss: 0.2301 - val_accuracy: 0.9182\n",
            "Epoch 112/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3899 - accuracy: 0.8480 - val_loss: 0.2295 - val_accuracy: 0.9212\n",
            "Epoch 113/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3927 - accuracy: 0.8328 - val_loss: 0.2293 - val_accuracy: 0.9182\n",
            "Epoch 114/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3794 - accuracy: 0.8366 - val_loss: 0.2281 - val_accuracy: 0.9212\n",
            "Epoch 115/200\n",
            "165/165 [==============================] - 21s 129ms/step - loss: 0.3754 - accuracy: 0.8457 - val_loss: 0.2277 - val_accuracy: 0.9242\n",
            "Epoch 116/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.4073 - accuracy: 0.8404 - val_loss: 0.2276 - val_accuracy: 0.9212\n",
            "Epoch 117/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3648 - accuracy: 0.8511 - val_loss: 0.2268 - val_accuracy: 0.9242\n",
            "Epoch 118/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3697 - accuracy: 0.8442 - val_loss: 0.2266 - val_accuracy: 0.9212\n",
            "Epoch 119/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.4158 - accuracy: 0.8381 - val_loss: 0.2266 - val_accuracy: 0.9212\n",
            "Epoch 120/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3820 - accuracy: 0.8404 - val_loss: 0.2259 - val_accuracy: 0.9242\n",
            "Epoch 121/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3792 - accuracy: 0.8419 - val_loss: 0.2250 - val_accuracy: 0.9212\n",
            "Epoch 122/200\n",
            "165/165 [==============================] - 21s 126ms/step - loss: 0.3915 - accuracy: 0.8412 - val_loss: 0.2245 - val_accuracy: 0.9212\n",
            "Epoch 123/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3980 - accuracy: 0.8503 - val_loss: 0.2240 - val_accuracy: 0.9212\n",
            "Epoch 124/200\n",
            "165/165 [==============================] - 21s 129ms/step - loss: 0.3790 - accuracy: 0.8427 - val_loss: 0.2238 - val_accuracy: 0.9273\n",
            "Epoch 125/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3791 - accuracy: 0.8533 - val_loss: 0.2240 - val_accuracy: 0.9242\n",
            "Epoch 126/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3807 - accuracy: 0.8495 - val_loss: 0.2236 - val_accuracy: 0.9242\n",
            "Epoch 127/200\n",
            "165/165 [==============================] - 21s 128ms/step - loss: 0.3853 - accuracy: 0.8549 - val_loss: 0.2223 - val_accuracy: 0.9303\n",
            "Epoch 128/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3724 - accuracy: 0.8549 - val_loss: 0.2217 - val_accuracy: 0.9303\n",
            "Epoch 129/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3835 - accuracy: 0.8495 - val_loss: 0.2219 - val_accuracy: 0.9273\n",
            "Epoch 130/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3843 - accuracy: 0.8374 - val_loss: 0.2210 - val_accuracy: 0.9303\n",
            "Epoch 131/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3917 - accuracy: 0.8495 - val_loss: 0.2211 - val_accuracy: 0.9273\n",
            "Epoch 132/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3382 - accuracy: 0.8640 - val_loss: 0.2204 - val_accuracy: 0.9273\n",
            "Epoch 133/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3620 - accuracy: 0.8404 - val_loss: 0.2199 - val_accuracy: 0.9303\n",
            "Epoch 134/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3708 - accuracy: 0.8495 - val_loss: 0.2203 - val_accuracy: 0.9273\n",
            "Epoch 135/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3593 - accuracy: 0.8556 - val_loss: 0.2199 - val_accuracy: 0.9273\n",
            "Epoch 136/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3489 - accuracy: 0.8640 - val_loss: 0.2192 - val_accuracy: 0.9273\n",
            "Epoch 137/200\n",
            "165/165 [==============================] - 21s 125ms/step - loss: 0.3663 - accuracy: 0.8442 - val_loss: 0.2189 - val_accuracy: 0.9273\n",
            "Epoch 138/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3497 - accuracy: 0.8571 - val_loss: 0.2185 - val_accuracy: 0.9273\n",
            "Epoch 139/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3259 - accuracy: 0.8731 - val_loss: 0.2179 - val_accuracy: 0.9273\n",
            "Epoch 140/200\n",
            "165/165 [==============================] - 20s 120ms/step - loss: 0.3822 - accuracy: 0.8465 - val_loss: 0.2174 - val_accuracy: 0.9273\n",
            "Epoch 141/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3639 - accuracy: 0.8427 - val_loss: 0.2169 - val_accuracy: 0.9273\n",
            "Epoch 142/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3627 - accuracy: 0.8526 - val_loss: 0.2165 - val_accuracy: 0.9303\n",
            "Epoch 143/200\n",
            "165/165 [==============================] - 20s 120ms/step - loss: 0.3489 - accuracy: 0.8587 - val_loss: 0.2160 - val_accuracy: 0.9303\n",
            "Epoch 144/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3508 - accuracy: 0.8609 - val_loss: 0.2157 - val_accuracy: 0.9303\n",
            "Epoch 145/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3755 - accuracy: 0.8480 - val_loss: 0.2158 - val_accuracy: 0.9273\n",
            "Epoch 146/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3488 - accuracy: 0.8670 - val_loss: 0.2158 - val_accuracy: 0.9273\n",
            "Epoch 147/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3851 - accuracy: 0.8442 - val_loss: 0.2154 - val_accuracy: 0.9273\n",
            "Epoch 148/200\n",
            "165/165 [==============================] - 20s 120ms/step - loss: 0.3736 - accuracy: 0.8450 - val_loss: 0.2153 - val_accuracy: 0.9273\n",
            "Epoch 149/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3527 - accuracy: 0.8579 - val_loss: 0.2157 - val_accuracy: 0.9273\n",
            "Epoch 150/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3559 - accuracy: 0.8579 - val_loss: 0.2151 - val_accuracy: 0.9273\n",
            "Epoch 151/200\n",
            "165/165 [==============================] - 20s 120ms/step - loss: 0.3528 - accuracy: 0.8632 - val_loss: 0.2159 - val_accuracy: 0.9242\n",
            "Epoch 152/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3372 - accuracy: 0.8663 - val_loss: 0.2145 - val_accuracy: 0.9273\n",
            "Epoch 153/200\n",
            "165/165 [==============================] - 20s 124ms/step - loss: 0.3660 - accuracy: 0.8450 - val_loss: 0.2142 - val_accuracy: 0.9273\n",
            "Epoch 154/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.4030 - accuracy: 0.8473 - val_loss: 0.2140 - val_accuracy: 0.9273\n",
            "Epoch 155/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3527 - accuracy: 0.8594 - val_loss: 0.2132 - val_accuracy: 0.9273\n",
            "Epoch 156/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3685 - accuracy: 0.8366 - val_loss: 0.2132 - val_accuracy: 0.9273\n",
            "Epoch 157/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3333 - accuracy: 0.8655 - val_loss: 0.2131 - val_accuracy: 0.9273\n",
            "Epoch 158/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3649 - accuracy: 0.8533 - val_loss: 0.2129 - val_accuracy: 0.9273\n",
            "Epoch 159/200\n",
            "165/165 [==============================] - 20s 121ms/step - loss: 0.3789 - accuracy: 0.8511 - val_loss: 0.2124 - val_accuracy: 0.9273\n",
            "Epoch 160/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3560 - accuracy: 0.8518 - val_loss: 0.2116 - val_accuracy: 0.9303\n",
            "Epoch 161/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3509 - accuracy: 0.8564 - val_loss: 0.2112 - val_accuracy: 0.9303\n",
            "Epoch 162/200\n",
            "165/165 [==============================] - 22s 131ms/step - loss: 0.3457 - accuracy: 0.8617 - val_loss: 0.2107 - val_accuracy: 0.9333\n",
            "Epoch 163/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3453 - accuracy: 0.8609 - val_loss: 0.2109 - val_accuracy: 0.9273\n",
            "Epoch 164/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3496 - accuracy: 0.8587 - val_loss: 0.2114 - val_accuracy: 0.9273\n",
            "Epoch 165/200\n",
            "165/165 [==============================] - 20s 124ms/step - loss: 0.3547 - accuracy: 0.8663 - val_loss: 0.2114 - val_accuracy: 0.9273\n",
            "Epoch 166/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3741 - accuracy: 0.8442 - val_loss: 0.2115 - val_accuracy: 0.9273\n",
            "Epoch 167/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3502 - accuracy: 0.8678 - val_loss: 0.2108 - val_accuracy: 0.9273\n",
            "Epoch 168/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3636 - accuracy: 0.8526 - val_loss: 0.2105 - val_accuracy: 0.9273\n",
            "Epoch 169/200\n",
            "165/165 [==============================] - 21s 124ms/step - loss: 0.3526 - accuracy: 0.8594 - val_loss: 0.2107 - val_accuracy: 0.9273\n",
            "Epoch 170/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3514 - accuracy: 0.8579 - val_loss: 0.2104 - val_accuracy: 0.9273\n",
            "Epoch 171/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3597 - accuracy: 0.8533 - val_loss: 0.2100 - val_accuracy: 0.9273\n",
            "Epoch 172/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3314 - accuracy: 0.8685 - val_loss: 0.2099 - val_accuracy: 0.9273\n",
            "Epoch 173/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3574 - accuracy: 0.8495 - val_loss: 0.2095 - val_accuracy: 0.9303\n",
            "Epoch 174/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3728 - accuracy: 0.8541 - val_loss: 0.2097 - val_accuracy: 0.9273\n",
            "Epoch 175/200\n",
            "165/165 [==============================] - 21s 124ms/step - loss: 0.3350 - accuracy: 0.8670 - val_loss: 0.2094 - val_accuracy: 0.9303\n",
            "Epoch 176/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3372 - accuracy: 0.8594 - val_loss: 0.2090 - val_accuracy: 0.9303\n",
            "Epoch 177/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3662 - accuracy: 0.8549 - val_loss: 0.2080 - val_accuracy: 0.9303\n",
            "Epoch 178/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3588 - accuracy: 0.8533 - val_loss: 0.2086 - val_accuracy: 0.9303\n",
            "Epoch 179/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3338 - accuracy: 0.8647 - val_loss: 0.2087 - val_accuracy: 0.9303\n",
            "Epoch 180/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3573 - accuracy: 0.8685 - val_loss: 0.2081 - val_accuracy: 0.9303\n",
            "Epoch 181/200\n",
            "165/165 [==============================] - 20s 124ms/step - loss: 0.3708 - accuracy: 0.8488 - val_loss: 0.2081 - val_accuracy: 0.9303\n",
            "Epoch 182/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3370 - accuracy: 0.8685 - val_loss: 0.2081 - val_accuracy: 0.9303\n",
            "Epoch 183/200\n",
            "165/165 [==============================] - 20s 124ms/step - loss: 0.3792 - accuracy: 0.8526 - val_loss: 0.2084 - val_accuracy: 0.9303\n",
            "Epoch 184/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3635 - accuracy: 0.8488 - val_loss: 0.2082 - val_accuracy: 0.9303\n",
            "Epoch 185/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3411 - accuracy: 0.8556 - val_loss: 0.2077 - val_accuracy: 0.9303\n",
            "Epoch 186/200\n",
            "165/165 [==============================] - 20s 122ms/step - loss: 0.3510 - accuracy: 0.8503 - val_loss: 0.2065 - val_accuracy: 0.9303\n",
            "Epoch 187/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3409 - accuracy: 0.8640 - val_loss: 0.2071 - val_accuracy: 0.9303\n",
            "Epoch 188/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3294 - accuracy: 0.8723 - val_loss: 0.2062 - val_accuracy: 0.9303\n",
            "Epoch 189/200\n",
            "165/165 [==============================] - 20s 123ms/step - loss: 0.3703 - accuracy: 0.8526 - val_loss: 0.2065 - val_accuracy: 0.9303\n",
            "Epoch 190/200\n",
            " 52/165 [========>.....................] - ETA: 12s - loss: 0.3338 - accuracy: 0.8726"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJuoDt_vOm6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "72508edc-40bd-48b0-fc89-9515482626d5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS59hlDt0MCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "497601dd-1b65-4257-c873-cbfc9f38ddb0"
      },
      "source": [
        "model.load_weights(checkpoint_filepath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2802103c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkIddz4COm3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHhRTlSqOm1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test1=pd.read_csv('/content/gdrive/My Drive/datasets/cnn_emergency_or_not/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeK1I-hOOmyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=[]\n",
        "for i in test1['image_names']:\n",
        "    image = tf.keras.preprocessing.image.load_img('/content/gdrive/My Drive/datasets/cnn_emergency_or_not/test/'+i,target_size=(224,224))\n",
        "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    input_arr = input_arr/255.\n",
        "    input_arr = np.expand_dims(input_arr,axis=0)  # Convert single image to a batch.\n",
        "    predictions.append(input_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypZMKYH9lxCK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94109e25-3740-49b3-bb3c-b5eda668786e"
      },
      "source": [
        "images = np.vstack(predictions)\n",
        "classes = model.predict(images)\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6.41275989e-03]\n",
            " [3.17206860e-01]\n",
            " [4.25419537e-03]\n",
            " [9.78683352e-01]\n",
            " [8.52936821e-04]\n",
            " [8.93865824e-01]\n",
            " [3.70801464e-02]\n",
            " [9.35613513e-01]\n",
            " [1.34129319e-02]\n",
            " [3.33954483e-01]\n",
            " [3.69626395e-02]\n",
            " [1.18497368e-02]\n",
            " [7.88458064e-03]\n",
            " [3.76471458e-03]\n",
            " [6.69554283e-04]\n",
            " [9.86939967e-01]\n",
            " [6.21376075e-02]\n",
            " [9.48977470e-01]\n",
            " [6.94559753e-01]\n",
            " [9.83869851e-01]\n",
            " [9.82119977e-01]\n",
            " [1.41366020e-01]\n",
            " [7.84973979e-01]\n",
            " [7.92064983e-03]\n",
            " [3.29455570e-03]\n",
            " [2.20565647e-02]\n",
            " [9.86080110e-01]\n",
            " [1.40837478e-02]\n",
            " [2.69880295e-01]\n",
            " [1.68766081e-01]\n",
            " [9.99144793e-01]\n",
            " [8.64369608e-03]\n",
            " [9.58686233e-01]\n",
            " [2.84999888e-03]\n",
            " [1.28043219e-01]\n",
            " [1.25965849e-02]\n",
            " [5.04100211e-02]\n",
            " [5.40313721e-01]\n",
            " [7.49290781e-03]\n",
            " [4.94043669e-03]\n",
            " [9.70573127e-01]\n",
            " [7.93037713e-01]\n",
            " [2.15989025e-03]\n",
            " [5.84265552e-02]\n",
            " [4.80265766e-02]\n",
            " [9.65702757e-02]\n",
            " [1.52907586e-02]\n",
            " [4.64055082e-03]\n",
            " [5.59331104e-02]\n",
            " [7.53573095e-03]\n",
            " [9.84324455e-01]\n",
            " [4.54502255e-01]\n",
            " [2.04046047e-03]\n",
            " [2.46080738e-02]\n",
            " [9.92929637e-01]\n",
            " [4.17755172e-03]\n",
            " [9.93984997e-01]\n",
            " [6.54918015e-01]\n",
            " [2.17136256e-02]\n",
            " [2.47975308e-02]\n",
            " [9.99717891e-01]\n",
            " [8.66617799e-01]\n",
            " [6.72054710e-03]\n",
            " [1.70041490e-02]\n",
            " [9.71265793e-01]\n",
            " [8.71383324e-02]\n",
            " [8.81385565e-01]\n",
            " [8.34452391e-01]\n",
            " [9.44954932e-01]\n",
            " [2.29833014e-02]\n",
            " [1.11565972e-03]\n",
            " [6.62359549e-03]\n",
            " [9.87621367e-01]\n",
            " [1.17932096e-01]\n",
            " [5.44480264e-01]\n",
            " [2.70133726e-02]\n",
            " [5.17048538e-02]\n",
            " [8.95153999e-01]\n",
            " [9.98584628e-01]\n",
            " [9.87573028e-01]\n",
            " [4.46591573e-03]\n",
            " [9.79019225e-01]\n",
            " [7.04392195e-01]\n",
            " [5.55440187e-01]\n",
            " [8.47125277e-02]\n",
            " [9.26161464e-03]\n",
            " [1.17408819e-02]\n",
            " [9.55402970e-01]\n",
            " [5.53696930e-01]\n",
            " [8.52562487e-01]\n",
            " [5.70700765e-01]\n",
            " [2.32465371e-01]\n",
            " [1.40954442e-02]\n",
            " [9.95275140e-01]\n",
            " [8.87685828e-03]\n",
            " [6.24505818e-01]\n",
            " [6.10206902e-01]\n",
            " [2.64805136e-03]\n",
            " [8.63730349e-03]\n",
            " [9.93400872e-01]\n",
            " [9.97033358e-01]\n",
            " [1.01912757e-02]\n",
            " [1.26587916e-02]\n",
            " [1.00076357e-02]\n",
            " [9.36715543e-01]\n",
            " [9.94779110e-01]\n",
            " [7.36553133e-01]\n",
            " [4.96571995e-02]\n",
            " [2.49644625e-03]\n",
            " [7.37181604e-02]\n",
            " [1.11629982e-02]\n",
            " [4.07247424e-01]\n",
            " [4.91357548e-03]\n",
            " [7.38135306e-03]\n",
            " [4.57684835e-03]\n",
            " [9.70868617e-02]\n",
            " [9.96567249e-01]\n",
            " [8.40704799e-01]\n",
            " [9.49639142e-01]\n",
            " [1.14101823e-02]\n",
            " [9.67283905e-01]\n",
            " [1.69821735e-02]\n",
            " [1.72255021e-02]\n",
            " [1.78800523e-02]\n",
            " [3.33917029e-02]\n",
            " [5.07672224e-03]\n",
            " [9.78872895e-01]\n",
            " [1.28731541e-02]\n",
            " [1.93539366e-01]\n",
            " [1.85368910e-01]\n",
            " [9.91186917e-01]\n",
            " [9.85975564e-01]\n",
            " [9.96289849e-01]\n",
            " [1.17944010e-01]\n",
            " [2.68318087e-01]\n",
            " [9.95197952e-01]\n",
            " [9.68149185e-01]\n",
            " [5.26215374e-01]\n",
            " [1.89681724e-03]\n",
            " [9.87815797e-01]\n",
            " [7.58430047e-04]\n",
            " [9.99371111e-01]\n",
            " [1.62176683e-03]\n",
            " [1.53466702e-01]\n",
            " [1.47273570e-01]\n",
            " [9.35790777e-01]\n",
            " [9.98409688e-01]\n",
            " [9.98194039e-01]\n",
            " [2.14106645e-02]\n",
            " [9.95893836e-01]\n",
            " [1.97670516e-02]\n",
            " [6.28694054e-03]\n",
            " [9.83180344e-01]\n",
            " [3.67601961e-02]\n",
            " [9.98919606e-01]\n",
            " [4.58286144e-02]\n",
            " [4.64914478e-02]\n",
            " [9.71124887e-01]\n",
            " [9.95934129e-01]\n",
            " [3.48104954e-01]\n",
            " [4.37181368e-02]\n",
            " [1.98550131e-02]\n",
            " [9.91747856e-01]\n",
            " [9.94960546e-01]\n",
            " [7.18488753e-01]\n",
            " [9.93610322e-01]\n",
            " [1.01127483e-01]\n",
            " [1.16784602e-01]\n",
            " [5.42998873e-03]\n",
            " [7.20033015e-04]\n",
            " [8.62678420e-03]\n",
            " [3.08635831e-03]\n",
            " [1.83763597e-02]\n",
            " [2.10753158e-02]\n",
            " [1.06191142e-02]\n",
            " [6.47586644e-01]\n",
            " [8.99430588e-02]\n",
            " [3.30442071e-01]\n",
            " [9.98476326e-01]\n",
            " [1.12796323e-02]\n",
            " [9.97181535e-01]\n",
            " [1.70732127e-03]\n",
            " [1.28900530e-02]\n",
            " [9.60149348e-01]\n",
            " [3.68844867e-01]\n",
            " [2.84669343e-02]\n",
            " [1.00190220e-02]\n",
            " [2.66337395e-03]\n",
            " [9.54832375e-01]\n",
            " [8.98525476e-01]\n",
            " [9.82974589e-01]\n",
            " [2.50490401e-02]\n",
            " [3.75041701e-02]\n",
            " [9.98859167e-01]\n",
            " [9.12731469e-01]\n",
            " [8.54855683e-03]\n",
            " [9.99113381e-01]\n",
            " [1.66732874e-02]\n",
            " [1.12429529e-01]\n",
            " [1.66824341e-01]\n",
            " [2.03388512e-01]\n",
            " [9.14886370e-02]\n",
            " [5.63779809e-02]\n",
            " [8.09157267e-02]\n",
            " [1.24010781e-03]\n",
            " [1.50029059e-03]\n",
            " [4.88257259e-02]\n",
            " [4.45725709e-01]\n",
            " [1.41124174e-01]\n",
            " [9.97812867e-01]\n",
            " [9.71926808e-01]\n",
            " [1.78602904e-01]\n",
            " [5.28360084e-02]\n",
            " [6.09295130e-01]\n",
            " [9.97496903e-01]\n",
            " [9.58417952e-01]\n",
            " [8.44943523e-01]\n",
            " [8.07182118e-02]\n",
            " [9.16465819e-01]\n",
            " [5.56157947e-01]\n",
            " [3.69068831e-01]\n",
            " [2.15409556e-03]\n",
            " [6.84827507e-01]\n",
            " [9.12090391e-03]\n",
            " [3.30670141e-02]\n",
            " [8.71903598e-01]\n",
            " [9.73534286e-01]\n",
            " [1.41641609e-02]\n",
            " [9.02530178e-02]\n",
            " [9.27548945e-01]\n",
            " [9.99736726e-01]\n",
            " [5.48256515e-03]\n",
            " [4.16761190e-02]\n",
            " [6.57710712e-03]\n",
            " [1.78446591e-01]\n",
            " [5.81368944e-03]\n",
            " [9.93024468e-01]\n",
            " [9.87425625e-01]\n",
            " [2.62776203e-03]\n",
            " [9.99361575e-01]\n",
            " [4.01674351e-03]\n",
            " [9.96270299e-01]\n",
            " [1.18263320e-04]\n",
            " [1.24069315e-03]\n",
            " [8.21097076e-01]\n",
            " [9.67773676e-01]\n",
            " [5.47328964e-02]\n",
            " [3.22810635e-02]\n",
            " [5.82013428e-02]\n",
            " [1.89418113e-03]\n",
            " [8.24018478e-01]\n",
            " [8.54048073e-01]\n",
            " [6.95628226e-01]\n",
            " [1.44450098e-01]\n",
            " [2.59419773e-02]\n",
            " [3.37661803e-01]\n",
            " [7.39443768e-03]\n",
            " [4.58602346e-02]\n",
            " [9.99405265e-01]\n",
            " [1.80677790e-02]\n",
            " [9.94458437e-01]\n",
            " [7.99776465e-02]\n",
            " [8.46240640e-01]\n",
            " [1.19530618e-01]\n",
            " [2.41187632e-01]\n",
            " [9.85301316e-01]\n",
            " [9.66661334e-01]\n",
            " [4.45509009e-04]\n",
            " [9.95978713e-01]\n",
            " [9.71296251e-01]\n",
            " [4.56438027e-03]\n",
            " [1.18059013e-03]\n",
            " [9.23471570e-01]\n",
            " [9.86960411e-01]\n",
            " [2.47544027e-03]\n",
            " [9.77366745e-01]\n",
            " [1.49788884e-02]\n",
            " [5.98998293e-02]\n",
            " [9.99081228e-03]\n",
            " [1.02776103e-01]\n",
            " [8.81130900e-03]\n",
            " [1.09924458e-01]\n",
            " [4.26063128e-03]\n",
            " [9.98748302e-01]\n",
            " [1.07066799e-02]\n",
            " [9.96237040e-01]\n",
            " [4.73373160e-02]\n",
            " [1.08209886e-01]\n",
            " [1.23593258e-02]\n",
            " [8.90934110e-01]\n",
            " [7.36653712e-03]\n",
            " [3.25141810e-02]\n",
            " [9.89985883e-01]\n",
            " [1.12521872e-02]\n",
            " [5.27457178e-01]\n",
            " [9.98874724e-01]\n",
            " [4.05861996e-02]\n",
            " [7.81553805e-01]\n",
            " [9.56222892e-01]\n",
            " [9.94211733e-01]\n",
            " [9.97815132e-01]\n",
            " [9.97940600e-01]\n",
            " [4.96562868e-02]\n",
            " [2.33904738e-03]\n",
            " [1.69079602e-02]\n",
            " [1.41124174e-01]\n",
            " [9.96443331e-01]\n",
            " [4.91607760e-04]\n",
            " [8.83541182e-02]\n",
            " [2.22030971e-02]\n",
            " [9.97951329e-01]\n",
            " [8.26627195e-01]\n",
            " [6.80323504e-03]\n",
            " [1.92792401e-01]\n",
            " [3.86195146e-02]\n",
            " [5.46776270e-03]\n",
            " [4.37908359e-02]\n",
            " [7.17238337e-02]\n",
            " [9.96034086e-01]\n",
            " [1.88502803e-01]\n",
            " [7.00640455e-02]\n",
            " [9.99604404e-01]\n",
            " [9.97121632e-01]\n",
            " [9.97693598e-01]\n",
            " [9.92358148e-01]\n",
            " [6.74132884e-01]\n",
            " [6.73855236e-03]\n",
            " [1.42394295e-02]\n",
            " [9.95432377e-01]\n",
            " [9.80865300e-01]\n",
            " [5.38780652e-02]\n",
            " [9.79689360e-01]\n",
            " [1.89296946e-01]\n",
            " [7.91381374e-02]\n",
            " [8.34742904e-01]\n",
            " [9.99014854e-01]\n",
            " [6.42472878e-02]\n",
            " [6.63384795e-02]\n",
            " [7.35291913e-02]\n",
            " [9.66773257e-02]\n",
            " [5.21715777e-03]\n",
            " [6.78164184e-01]\n",
            " [9.99081228e-03]\n",
            " [9.98132646e-01]\n",
            " [9.88484561e-01]\n",
            " [3.22293909e-03]\n",
            " [9.86514270e-01]\n",
            " [1.13554217e-01]\n",
            " [1.96571685e-02]\n",
            " [9.88257587e-01]\n",
            " [5.64170837e-01]\n",
            " [9.16503906e-01]\n",
            " [9.68588173e-01]\n",
            " [8.72454606e-03]\n",
            " [4.97894846e-02]\n",
            " [6.34039164e-01]\n",
            " [4.79210503e-02]\n",
            " [2.63769936e-04]\n",
            " [7.56073296e-01]\n",
            " [4.17755172e-03]\n",
            " [9.99906182e-01]\n",
            " [9.97304201e-01]\n",
            " [2.41332757e-03]\n",
            " [9.87584651e-01]\n",
            " [9.05376300e-03]\n",
            " [8.28523397e-01]\n",
            " [5.50984126e-03]\n",
            " [9.09383416e-01]\n",
            " [1.46637792e-02]\n",
            " [9.99167323e-01]\n",
            " [7.88458064e-03]\n",
            " [2.47975308e-02]\n",
            " [6.60021883e-03]\n",
            " [4.40710634e-02]\n",
            " [4.04914260e-01]\n",
            " [8.59590247e-03]\n",
            " [1.07555995e-02]\n",
            " [1.52049912e-02]\n",
            " [4.27212231e-02]\n",
            " [9.69762444e-01]\n",
            " [1.26166893e-02]\n",
            " [5.54833353e-01]\n",
            " [3.68524482e-03]\n",
            " [2.29928866e-02]\n",
            " [5.28250098e-01]\n",
            " [6.67693466e-02]\n",
            " [9.96710896e-01]\n",
            " [2.89463531e-02]\n",
            " [2.58116066e-01]\n",
            " [9.45477486e-01]\n",
            " [1.36258733e-03]\n",
            " [1.93715002e-02]\n",
            " [9.92358625e-01]\n",
            " [9.84048843e-01]\n",
            " [9.87993002e-01]\n",
            " [3.55369188e-02]\n",
            " [4.91366833e-02]\n",
            " [8.18717420e-01]\n",
            " [1.35920309e-02]\n",
            " [5.48642389e-02]\n",
            " [9.12332628e-03]\n",
            " [9.43432689e-01]\n",
            " [1.15903944e-01]\n",
            " [9.99660254e-01]\n",
            " [9.98621821e-01]\n",
            " [6.58842802e-01]\n",
            " [9.96722877e-01]\n",
            " [5.15409261e-02]\n",
            " [3.46058190e-01]\n",
            " [3.13877046e-01]\n",
            " [8.91477764e-01]\n",
            " [1.17736012e-01]\n",
            " [4.13086750e-02]\n",
            " [9.98380780e-01]\n",
            " [9.17327225e-01]\n",
            " [2.47781530e-01]\n",
            " [8.38300511e-02]\n",
            " [1.06510378e-01]\n",
            " [9.52742398e-01]\n",
            " [9.53014910e-01]\n",
            " [5.22797368e-03]\n",
            " [1.62500795e-03]\n",
            " [1.82865396e-01]\n",
            " [9.55923378e-01]\n",
            " [3.70662957e-01]\n",
            " [1.12341833e-03]\n",
            " [9.31450307e-01]\n",
            " [7.84220040e-01]\n",
            " [1.59881741e-01]\n",
            " [7.86150694e-02]\n",
            " [9.67662394e-01]\n",
            " [9.70011055e-01]\n",
            " [2.93678441e-03]\n",
            " [4.85411333e-03]\n",
            " [2.47814995e-03]\n",
            " [9.97638106e-01]\n",
            " [6.07809518e-03]\n",
            " [9.21515167e-01]\n",
            " [9.98647869e-01]\n",
            " [6.33121375e-03]\n",
            " [9.96926367e-01]\n",
            " [5.79647254e-03]\n",
            " [9.93611038e-01]\n",
            " [5.59331104e-02]\n",
            " [9.94612813e-01]\n",
            " [1.44499040e-03]\n",
            " [8.71501397e-04]\n",
            " [9.99359190e-01]\n",
            " [9.68927704e-03]\n",
            " [1.69745032e-02]\n",
            " [6.98743528e-03]\n",
            " [6.16670772e-02]\n",
            " [2.76332684e-02]\n",
            " [9.06572044e-01]\n",
            " [9.88480806e-01]\n",
            " [3.33564550e-01]\n",
            " [9.19370055e-01]\n",
            " [3.99364263e-01]\n",
            " [6.73357695e-02]\n",
            " [4.80265766e-02]\n",
            " [2.07561590e-02]\n",
            " [1.89804984e-03]\n",
            " [1.72618315e-01]\n",
            " [1.51012151e-03]\n",
            " [8.07080567e-01]\n",
            " [9.92906213e-01]\n",
            " [2.45882338e-03]\n",
            " [9.97156143e-01]\n",
            " [2.85258174e-01]\n",
            " [3.87990102e-02]\n",
            " [1.41856559e-02]\n",
            " [9.90062356e-01]\n",
            " [9.99360859e-01]\n",
            " [9.63522613e-01]\n",
            " [9.88882363e-01]\n",
            " [9.51728702e-01]\n",
            " [2.49934811e-02]\n",
            " [9.99683022e-01]\n",
            " [9.61510301e-01]\n",
            " [1.03476765e-02]\n",
            " [7.33483553e-01]\n",
            " [9.49853480e-01]\n",
            " [1.24069315e-03]\n",
            " [2.26254668e-02]\n",
            " [1.02862321e-01]\n",
            " [7.17863142e-01]\n",
            " [1.30119380e-02]\n",
            " [9.37514961e-01]\n",
            " [9.70478263e-03]\n",
            " [7.13782489e-01]\n",
            " [3.68677974e-02]\n",
            " [9.94229078e-01]\n",
            " [9.99914169e-01]\n",
            " [3.58302861e-01]\n",
            " [4.00439557e-03]\n",
            " [2.81133294e-01]\n",
            " [3.44453782e-01]\n",
            " [1.68007135e-01]\n",
            " [9.99472201e-01]\n",
            " [2.04098760e-03]\n",
            " [9.70838845e-01]\n",
            " [9.94341254e-01]\n",
            " [1.97956618e-03]\n",
            " [7.24559188e-01]\n",
            " [8.55920389e-02]\n",
            " [2.22496223e-02]\n",
            " [1.67414770e-02]\n",
            " [1.09785393e-01]\n",
            " [9.64035094e-01]\n",
            " [7.39020528e-04]\n",
            " [4.11416870e-03]\n",
            " [9.98635948e-01]\n",
            " [8.70008409e-01]\n",
            " [3.89659981e-04]\n",
            " [5.05752163e-03]\n",
            " [9.82119977e-01]\n",
            " [9.61086512e-01]\n",
            " [9.32542503e-01]\n",
            " [2.35042218e-02]\n",
            " [6.21376075e-02]\n",
            " [2.28611324e-02]\n",
            " [3.24735865e-02]\n",
            " [6.93956077e-01]\n",
            " [3.54934880e-03]\n",
            " [1.84821546e-01]\n",
            " [5.20262361e-01]\n",
            " [9.84195709e-01]\n",
            " [3.29076797e-01]\n",
            " [7.23398000e-04]\n",
            " [4.70828544e-03]\n",
            " [9.04331982e-01]\n",
            " [9.91694391e-01]\n",
            " [1.49109334e-01]\n",
            " [1.98894162e-02]\n",
            " [9.91895143e-03]\n",
            " [3.23823206e-02]\n",
            " [3.71320844e-01]\n",
            " [9.76570189e-01]\n",
            " [7.76218809e-03]\n",
            " [9.91630137e-01]\n",
            " [9.30720210e-01]\n",
            " [4.53831442e-02]\n",
            " [9.12090391e-03]\n",
            " [5.87632600e-03]\n",
            " [9.97196436e-01]\n",
            " [9.80039179e-01]\n",
            " [7.80314267e-01]\n",
            " [3.07494367e-04]\n",
            " [9.81265247e-01]\n",
            " [4.59439129e-01]\n",
            " [4.06623572e-01]\n",
            " [1.24220492e-03]\n",
            " [1.32360801e-01]\n",
            " [1.05463825e-01]\n",
            " [5.79899317e-03]\n",
            " [5.80340847e-02]\n",
            " [3.99855793e-01]\n",
            " [3.93739203e-04]\n",
            " [9.79682088e-01]\n",
            " [2.04258203e-03]\n",
            " [2.75939628e-02]\n",
            " [9.94688511e-01]\n",
            " [9.65953887e-01]\n",
            " [9.13533941e-03]\n",
            " [9.69766498e-01]\n",
            " [9.18061733e-01]\n",
            " [7.20735729e-01]\n",
            " [9.90640640e-01]\n",
            " [2.65045743e-02]\n",
            " [4.84513352e-03]\n",
            " [1.19416108e-02]\n",
            " [8.15572776e-03]\n",
            " [9.62611973e-01]\n",
            " [7.46228099e-02]\n",
            " [7.52452388e-03]\n",
            " [9.60993767e-01]\n",
            " [9.91767764e-01]\n",
            " [1.61417834e-02]\n",
            " [3.71248112e-04]\n",
            " [9.63477790e-01]\n",
            " [8.82560480e-03]\n",
            " [9.96461213e-01]\n",
            " [9.55904961e-01]\n",
            " [9.84277010e-01]\n",
            " [5.49221784e-02]\n",
            " [2.26254668e-02]\n",
            " [1.14645258e-01]\n",
            " [5.21109067e-03]\n",
            " [6.14592806e-03]\n",
            " [2.89714010e-03]\n",
            " [2.57946402e-01]\n",
            " [3.46606076e-02]\n",
            " [3.91615301e-01]\n",
            " [2.27229241e-02]\n",
            " [1.29414834e-02]\n",
            " [2.68956959e-01]\n",
            " [2.22293250e-02]\n",
            " [9.95833278e-01]\n",
            " [8.35166931e-01]\n",
            " [1.20290951e-03]\n",
            " [6.27160491e-03]\n",
            " [3.20797414e-01]\n",
            " [4.93502431e-02]\n",
            " [4.59259413e-02]\n",
            " [3.97012234e-01]\n",
            " [1.07435480e-01]\n",
            " [2.51771566e-02]\n",
            " [9.94911492e-01]\n",
            " [2.09268997e-03]\n",
            " [9.52600777e-01]\n",
            " [9.72489953e-01]\n",
            " [3.34638268e-01]\n",
            " [8.45835745e-01]\n",
            " [9.98836100e-01]\n",
            " [9.58320737e-01]\n",
            " [8.49306136e-02]\n",
            " [3.54229398e-02]\n",
            " [7.45288074e-01]\n",
            " [9.48172450e-01]\n",
            " [1.38010550e-03]\n",
            " [9.92354035e-01]\n",
            " [1.09821461e-01]\n",
            " [3.75670232e-02]\n",
            " [1.88181922e-02]\n",
            " [2.58595659e-03]\n",
            " [9.65652764e-01]\n",
            " [8.33712697e-01]\n",
            " [6.73051632e-04]\n",
            " [9.97498572e-01]\n",
            " [2.39202548e-02]\n",
            " [1.15718704e-03]\n",
            " [6.14592806e-03]\n",
            " [9.98317599e-01]\n",
            " [1.11901745e-01]\n",
            " [1.59646034e-01]\n",
            " [7.88575795e-04]\n",
            " [9.69883859e-01]\n",
            " [9.96283472e-01]\n",
            " [9.29107845e-01]\n",
            " [3.70801464e-02]\n",
            " [7.84489274e-01]\n",
            " [2.08648797e-02]\n",
            " [4.98252690e-01]\n",
            " [2.77987798e-03]\n",
            " [6.40010554e-03]\n",
            " [4.01907772e-01]\n",
            " [9.92570698e-01]\n",
            " [9.98795629e-01]\n",
            " [9.68431711e-01]\n",
            " [9.85853910e-01]\n",
            " [1.26632862e-03]\n",
            " [3.50542404e-02]\n",
            " [1.75450519e-01]\n",
            " [9.94140804e-01]\n",
            " [9.62533534e-01]\n",
            " [9.80354249e-01]\n",
            " [6.20725527e-02]\n",
            " [9.60327983e-01]\n",
            " [8.67726188e-03]\n",
            " [1.10886768e-02]\n",
            " [9.72952664e-01]\n",
            " [5.71377799e-02]\n",
            " [9.57103908e-01]\n",
            " [8.27739947e-04]\n",
            " [8.02975476e-01]\n",
            " [9.32894826e-01]\n",
            " [7.73091316e-02]\n",
            " [9.47604775e-01]\n",
            " [7.99865127e-01]\n",
            " [2.61463989e-02]\n",
            " [9.67014372e-01]\n",
            " [9.08744216e-01]\n",
            " [9.87067163e-01]\n",
            " [2.84924228e-02]\n",
            " [2.20237439e-03]\n",
            " [9.99815285e-01]\n",
            " [9.93167698e-01]\n",
            " [3.93659249e-03]\n",
            " [2.31327564e-02]\n",
            " [7.19740894e-03]\n",
            " [3.87990102e-02]\n",
            " [9.45692360e-01]\n",
            " [9.46465492e-01]\n",
            " [1.69353988e-02]\n",
            " [3.98882441e-02]\n",
            " [3.35899778e-02]\n",
            " [9.93078053e-01]\n",
            " [7.16443479e-01]\n",
            " [2.57037468e-02]\n",
            " [1.86853681e-03]\n",
            " [2.25771546e-01]\n",
            " [8.75353627e-03]\n",
            " [9.95782614e-01]\n",
            " [9.82005835e-01]\n",
            " [7.94527121e-03]\n",
            " [5.49425244e-01]\n",
            " [9.93850470e-01]\n",
            " [1.19339442e-02]\n",
            " [3.25625598e-01]\n",
            " [3.58976237e-02]\n",
            " [1.04965372e-02]\n",
            " [9.86851633e-01]\n",
            " [2.06279662e-02]\n",
            " [9.71766949e-01]\n",
            " [7.99023174e-03]\n",
            " [9.50227976e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eSPGzTDtr95",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3438881-d01a-4db4-e2cd-b8d8781caf9e"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 0, '1': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOEHhSc-zceI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBnAaz1BOmvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission=pd.read_csv('/content/gdrive/My Drive/datasets/cnn_emergency_or_not/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E38-KtpLOmtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred=np.array(classes)\n",
        "pred=pred.reshape((706,))\n",
        "for i in range(706):\n",
        "  if pred[i]<0.5:\n",
        "    pred[i]=0\n",
        "  else:\n",
        "    pred[i]=1\n",
        "\n",
        "\n",
        "\n",
        "submission['emergency_or_not']=pred\n",
        "\n",
        "submission=submission.set_index('image_names',drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylOFRXBWOmqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub=submission.to_csv('so2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oedDPLLLOmn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c748e5d-c1b4-41f5-d93c-7b4b3516eac6"
      },
      "source": [
        "pred[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUxr7XSCOl-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}